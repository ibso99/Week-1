{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION ANALYSIS FOR THE NEWS AND STOCK DATASETS\n",
    "FOR THE ALL STOCK DATA SET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns            # For advanced and aesthetically pleasing visualizations\n",
    "\n",
    "# Text Analysis (Sentiment and NLP)\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer  \n",
    "from textblob import TextBlob                          \n",
    "from wordcloud import WordCloud                       \n",
    "\n",
    "# Time-Series Analysis\n",
    "import datetime as dt  # For handling date and time-related operations\n",
    "\n",
    "# Machine Learning (if needed for advanced analysis later)\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer  \n",
    "from sklearn.decomposition import LatentDirichletAllocation                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_merger(df1_path, df2_path, ticker: str):\n",
    "    ''' the following function performs data loading and cleaning for the stock data news and \n",
    "    Stockn data prices and then it merges them by their dates and their tickers and returns a merged data frame\n",
    "    which simplifies for doing correlation analysis'''\n",
    "\n",
    "    # Preprocessing the first DataFrame (df1)\n",
    "    df1 = pd.read_csv(df1_path)\n",
    "    df1['date'] = pd.to_datetime(df1['date'], format='ISO8601', utc=True).dt.date\n",
    "    df1 = df1.drop(columns=[\"Unnamed: 0\"], errors='ignore')  # Drop if exists\n",
    "    # print(\"df1 columns:\", df1.columns) # for debugging purposes\n",
    "\n",
    "    # Preprocessing the second DataFrame (df2)\n",
    "    df2 = pd.read_csv(df2_path)\n",
    "    df2['Date'] = pd.to_datetime(df2['Date'], format='ISO8601', utc=True).dt.date\n",
    "    df2.rename(columns={'Date': 'date'}, inplace=True)\n",
    "    df2['Daily_Return'] = df2['Close'].pct_change()\n",
    "    # print(\"df2 columns:\", df2.columns) # for debugging purposes\n",
    "\n",
    "    # Filter selected stocks and the specific ticker\n",
    "    selected_categories = ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'NVDA', 'AMZN', 'META']\n",
    "    df1_selected = df1[df1['stock'].isin(selected_categories)]\n",
    "    df1_filtered = df1_selected[df1_selected['stock'] == ticker]\n",
    "\n",
    "    # Merge DataFrames\n",
    "    Merged_df = pd.merge(df1_filtered, df2, on='date', how='inner')\n",
    "    # print(\"Merged_df columns:\", Merged_df.columns) # for debugging purposes\n",
    "\n",
    "    # Check if 'headline' column exists\n",
    "    if 'headline' not in Merged_df.columns:\n",
    "        raise KeyError(\"'headline' column is missing in the merged DataFrame.\")\n",
    "\n",
    "    # Sentiment analysis\n",
    "    def calculate_sentiment(text):\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "\n",
    "    Merged_df['sentiment_score'] = Merged_df['headline'].apply(calculate_sentiment)\n",
    "\n",
    "    # Classify sentiment\n",
    "    Merged_df['sentiment_category'] = pd.cut(\n",
    "        Merged_df['sentiment_score'],\n",
    "        bins=[-1, -0.1, 0.1, 1],\n",
    "        labels=['negative', 'neutral', 'positive']\n",
    "    )\n",
    "\n",
    "    return Merged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION CALCULATION FOR ALL THE DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between sentiment score and daily stock returns of AAPL: 0.06662652819832401\n",
      "Correlation between sentiment score and closing price of AAPL: 0.05496089526508538\n",
      "Correlation between sentiment score and daily stock returns of GOOGL: 0.02707079024818816\n",
      "Correlation between sentiment score and closing price of GOOGL: -0.009027053700049099\n",
      "Correlation between sentiment score and daily stock returns of MSFT: nan\n",
      "Correlation between sentiment score and closing price of MSFT: nan\n",
      "Correlation between sentiment score and daily stock returns of TSLA: 0.024454665434566786\n",
      "Correlation between sentiment score and closing price of TSLA: -0.02632867605746522\n",
      "Correlation between sentiment score and daily stock returns of NVDA: 0.08485831064829649\n",
      "Correlation between sentiment score and closing price of NVDA: -0.011296696192418004\n",
      "Correlation between sentiment score and daily stock returns of AMZN: 0.006157753052171696\n",
      "Correlation between sentiment score and closing price of AMZN: 0.0861679165553202\n",
      "Correlation between sentiment score and daily stock returns of META: nan\n",
      "Correlation between sentiment score and closing price of META: nan\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of paths\n",
    "Path_Dict = {\n",
    "    'AAPL_PATH': \"C:/Users/ibsan/Desktop/TenX/week-1/Data/yfinance_data/AAPL_historical_data.csv\",\n",
    "    'AMZN_PATH': \"C:/Users/ibsan/Desktop/TenX/week-1/Data/yfinance_data/AMZN_historical_data.csv\",\n",
    "    'GOOGL_PATH': \"C:/Users/ibsan/Desktop/TenX/week-1/Data/yfinance_data/GOOG_historical_data.csv\",\n",
    "    'META_PATH': \"C:/Users/ibsan/Desktop/TenX/week-1/Data/yfinance_data/META_historical_data.csv\",\n",
    "    'MSFT_PATH': \"C:/Users/ibsan/Desktop/TenX/week-1/Data/yfinance_data/MSFT_historical_data.csv\",\n",
    "    'NVDA_PATH': \"C:/Users/ibsan/Desktop/TenX/week-1/Data/yfinance_data/NVDA_historical_data.csv\",\n",
    "    'TSLA_PATH': \"C:/Users/ibsan/Desktop/TenX/week-1/Data/yfinance_data/TSLA_historical_data.csv\"\n",
    "}\n",
    "\n",
    "# List of tickers\n",
    "tickers_list = ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'NVDA', 'AMZN', 'META']\n",
    "\n",
    "# Path to raw analyst ratings\n",
    "stock_path = \"C:/Users/ibsan/Desktop/TenX/week-1/Data/raw_analyst_ratings.csv/raw_analyst_ratings.csv\"\n",
    "\n",
    "# Loop to process and calculate correlations\n",
    "for i in range(len(tickers_list)):\n",
    "    ticker = tickers_list[i]\n",
    "    df2_path = Path_Dict[ticker + '_PATH']  # Fetch correct file path\n",
    "    \n",
    "    # Call the Data_merger function\n",
    "    temps_df = Data_merger(stock_path, df2_path, ticker=ticker)\n",
    "    \n",
    "    # Calculate correlations\n",
    "    corr_sent_score_and_daily_return = temps_df['sentiment_score'].corr(temps_df['Daily_Return'])\n",
    "    corr_sent_score_and_closing_price = temps_df['sentiment_score'].corr(temps_df['Close'])\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Correlation between sentiment score and daily stock returns of {ticker}: {corr_sent_score_and_daily_return}\")\n",
    "    print(f\"Correlation between sentiment score and closing price of {ticker}: {corr_sent_score_and_closing_price}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenxvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
